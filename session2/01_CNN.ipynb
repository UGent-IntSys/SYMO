{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session: Convolutional Neural Networks (CNN) \n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a type of deep learning model particularly effective for processing and analyzing visual data like images and videos. CNNs use a special structure that allows them to automatically and adaptively learn spatial hierarchies of features. This is done through layers like convolutional layers, pooling layers, and fully connected layers. Convolutional layers apply filters to the input, capturing essential patterns such as edges, textures, and shapes. This makes CNNs especially powerful for tasks like image classification, object detection, and facial recognition.\n",
    "\n",
    "<img width=\"600\" alt=\"image\" src=\"https://saturncloud.io/images/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way.webp\">\n",
    "\n",
    "## Overview\n",
    "\n",
    "This practical session focuses on using Convolutional Neural Networks (CNNs) to classify images into ten distinct categories, utilizing the `Fashion-MNIST` dataset.\n",
    "\n",
    "### Key Objectives:\n",
    "- **Grasping the Fundamentals of CNNs:** Gain a solid understanding of how CNNs function, including their role in image classification tasks.\n",
    "- **Exploring Layer Functionality:** Learn how different layers in a CNN contribute to feature extraction and classification, transforming raw image data into meaningful predictions.\n",
    "- **Constructing a Basic CNN Model:** Build a simple yet effective CNN model tailored to the Fashion-MNIST dataset, applying best practices in model architecture.\n",
    "- **Training the CNN Model:** Train the CNN model, understanding the role of epochs, batch sizes, and the learning process involved in optimizing the model’s performance.\n",
    "- **Evaluating Model Performance:** Assess the accuracy and effectiveness of your CNN model using appropriate evaluation metrics and visualization techniques.\n",
    "- **Tuning CNN Hyperparameters:** Experiment with and manipulate key hyperparameters to improve model performance and gain deeper insights into CNN optimization.\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "`Fashion-MNIST` is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. \n",
    "\n",
    "<img width=\"400\" alt=\"image\" src=\"https://i.imgur.com/BxGMWW4.png\">\n",
    "\n",
    "\n",
    "You can use direct links to download the dataset or use the folder `/data`.\n",
    "\n",
    "- Original source: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "Folder `/data` includes a column based format of this dataset: \n",
    "- `fashion-mnist_train.csv`\n",
    "- `fashion-mnist_test.csv`\n",
    "\n",
    "A quick description of these files: \n",
    "\n",
    "- Each image measures 28 by 28 pixels, totaling 784 pixels.\n",
    "- Every pixel has a corresponding value that reflects its brightness, with higher values indicating a darker shade. These values range from 0 to 255.\n",
    "- Both the training and test datasets contain 785 columns.\n",
    "- The first column holds the class labels, representing the type of clothing item.\n",
    "- The remaining 784 columns (1-785) store the pixel values for the corresponding image.\n",
    "\n",
    "\n",
    "### Labels\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries \n",
    "\n",
    "# Base libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualisation \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"tensorflow v.\"+tf.__version__)\n",
    "\n",
    "## Default options and global variables\n",
    "# Set number of decimal points to float type\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "pd.set_option('display.precision', 2)\n",
    "SEED = 2024\n",
    "N_CLASSES = 10\n",
    "keras.utils.set_random_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data path \n",
    "DATA_PATH=\"../data/Fashion-MNIST/\"\n",
    "\n",
    "# Data loading\n",
    "df_train = pd.read_csv(DATA_PATH + \"fashion-mnist_train.csv.zip\")\n",
    "df_test = pd.read_csv(DATA_PATH + \"fashion-mnist_test.csv.zip\")\n",
    "\n",
    "# Data dimension \n",
    "print(\"Train set:\",df_train.shape[0],\"rows,\",  df_train.shape[1], \"columns\")\n",
    "print(\"Test set :\",df_test.shape[0],\"rows,\",  df_test.shape[1], \"columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick exploration \n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels  \n",
    "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def plot_label_distributions (data, info):\n",
    "    plt.figure(figsize=(6,2))\n",
    "    unique_labels, data_counts = np.unique(data, return_counts=True)\n",
    "    sns.barplot(x=unique_labels, y=data_counts)\n",
    "    # labeling the plot\n",
    "    plt.xticks( unique_labels, labels, rotation=60)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of each class - ' + info)\n",
    "\n",
    "plot_label_distributions(df_train['label'], \"train\")\n",
    "plot_label_distributions(df_test['label'], \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subsampling ~ 50% \n",
    "df_train_sample = df_train.sample(n=30000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_label_distributions(df_train_sample['label'], \"Subsampled train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "\n",
    "We use [tf.keras](https://www.tensorflow.org/guide/keras) to build and train models. Keras is the high-level API of the TensorFlow platform. It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning.\n",
    "\n",
    "The `tf.keras.Model` class features built-in training and evaluation methods:\n",
    "\n",
    "- `tf.keras.Model.fit`: Trains the model for a fixed number of epochs.\n",
    "- `tf.keras.Model.predict`: Generates output predictions for the input samples.\n",
    "- `tf.keras.Model.evaluate`: Returns the loss and metrics values for the model; configured via the `tf.keras.Model.compile` method.\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset preparation \n",
    "\n",
    "# Variables for modelling\n",
    "#x_train = df_train.drop(columns=['label']).values\n",
    "#y_train = df_train[['label']].values\n",
    "x_train = df_train_sample.drop(columns=['label']).values\n",
    "y_train = df_train_sample[['label']].values\n",
    "x_test = df_test.drop(columns=['label']).values\n",
    "y_test = df_test[['label']].values\n",
    "\n",
    "# Reshaping the colums 784 (one dimensional format) to 28x28 (two dimensional array)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test  = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Alternative, you can fetch the \"Fashion MNIST\" data from Keras. \n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Use OneHotEncoder to encode target column ~ binary representation \n",
    "y_train = to_categorical(y_train, num_classes=N_CLASSES)\n",
    "y_test  = to_categorical(y_test, num_classes=N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Training Image Data: \" + str(x_train.shape))\n",
    "print(\"Shape of Training Class Data: \" + str(y_train.shape))\n",
    "print(\"Shape of Test Image Data: \" + str(x_test.shape))\n",
    "print(\"Shape of Test Class Data: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax( y_train[2])\n",
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot few images \n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel( labels[np.argmax(y_train[i])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "model = Sequential() # The sequential model is a linear stack of layers. Add layers by using the `add` method \n",
    "# Layers \n",
    "model.add( Flatten())\n",
    "model.add( Dense(128, activation='tanh'))\n",
    "model.add( Dense(N_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model compilation\n",
    "\n",
    "Before the model is ready for training, a few additional settings need to be configured during the model's compile step:\n",
    "\n",
    "- **Loss Function**: Measures the model's accuracy during training. The goal is to minimize this loss, guiding the model to improve its predictions.\n",
    "- **Optimizer**: Updates the model's parameters based on the data and loss. This helps the model learn from its errors.\n",
    "- **Metrics**: Track the model's performance during training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model compliation \n",
    "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.1)\n",
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer= optimizer,\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model vis\n",
    "model.build(input_shape=(None, 28,28,1)) # needed when the input_shape is not defined\n",
    "model.summary()\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH=64\n",
    "EPOCHS=12\n",
    "\n",
    "history_model = model.fit(x_train, y_train,\n",
    "                  batch_size=BATCH,\n",
    "                  epochs=EPOCHS,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "#%matplotlib inline\n",
    "\n",
    "def plot_model_history (history_model):\n",
    "    fig, (ax2, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(10, 3))\n",
    "    # loss\n",
    "    ax1.plot(history_model.history['loss'], label='Train Loss')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax1.legend()\n",
    "    # accuracy\n",
    "    ax2.plot(history_model.history['accuracy'], label='Train Accuracy')\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2.legend()\n",
    "\n",
    "plot_model_history(history_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A prediction is an array of the confidence values that correspont to each category (label)\n",
    "predictions[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label with the highest confidence\n",
    "np.argmax(predictions[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "def plot_prediction(i, predictions, true_label, img):\n",
    "  predictions, true_label, img = predictions[i], true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  \n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(labels[predicted_label],\n",
    "                                100*np.max(predictions),\n",
    "                                labels[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_prediction_confidence(i, predictions, true_label):\n",
    "  predictions, true_label = predictions[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  #plt.xticks()\n",
    "  plt.xticks( range(N_CLASSES), labels, rotation=80)\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(N_CLASSES), predictions, color=\"#777777\")\n",
    "  plt.ylim([0, 1]) \n",
    "  predicted_label = np.argmax(predictions)\n",
    " \n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 90\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_prediction(i, predictions, df_test['label'], x_test)\n",
    "plt.subplot(1,2,2)\n",
    "plot_prediction_confidence(i, predictions,  df_test['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "##Create Multiclass Confusion Matrix\n",
    "def plot_confusion_matrix(predictions, y_test):\n",
    "    cm = confusion_matrix(np.argmax(y_test,axis=1), np.argmax(predictions,axis=1))\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm,cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix - Fashion-MNIST')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(N_CLASSES), labels, rotation=90)\n",
    "    plt.yticks(range(N_CLASSES), labels)\n",
    "\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > 500 else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model\n",
    "\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".envTF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
